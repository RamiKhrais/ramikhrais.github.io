<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Linear Regression Analysis: Estimation of the Aggregate Consumption Equation</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<link rel="stylesheet" href="../assets/css/obsidian.css">
		<meta name="image" property="og:image" content="https://ramikhrais.github.io/ramikhrais.github.io/images/regression-analysis-01.png">
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
		<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	</head>

	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="../index.html" class="logo">Portfolio</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<!-- <ul class="links">
							<li><a href="index.html">This is Massively</a></li>
							<li class="active"><a href="generic.html">Generic Page</a></li>
							<li><a href="elements.html">Elements Reference</a></li>
						</ul> -->
						<!-- <ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul> -->
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">November 20, 2020</span>
									<h1>Linear Regression Analysis: Estimation of the Aggregate Consumption Equation<br />
									</h1>

									<p>In this project, I have used the linear regression model in order to investigate<br>the relationship between the disposable income per capita and the aggregate demand<br>in the Palestinian territories.</p>
									
                                </header>
                                

                                <h2>Introduction</h2>

								<p>A simple linear regression is a statistical model that allows us to analyse the relationship between a dependent variable (response) and independent variable (predictor). The model is considered as one of the most popular mathematical techniques to predict the value of the outcome variable based on one or more input predictor variables. It has been used for ages as a simple and straightforward approach in studying the linear relationships in a wide spectrum of fields ranging from economics to biology and it takes the following formula:</p>


								<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
									<mtable displaystyle="true">
									  <mlabeledtr>
										<mtd id="mjx-eqn-1">
										  <mtext></mtext>
										</mtd>
										<mtd>
										  <mi>Y</mi>
										  <mo>=</mo>
										  <msub>
											<mi>&#x03B2;<!-- ?? --></mi>
											<mn>0</mn>
										  </msub>
										  <mo>+</mo>
										  <msub>
											<mi>&#x03B2;<!-- ?? --></mi>
											<mn></mn>
										  </msub>
										  <mi>X</mi>
										  <mo>+</mo>
										  <mi>&#x03F5;<!-- ?? --></mi>
										</mtd>
									  </mlabeledtr>
									</mtable>
								  </math>

								<p>where:</p>

								<p>Y  represents the dependent (response) variable.</p>
								<p>X  represents the independent (predictor) variable.</p>
								<p><strong><span class="math inline">\({\beta}_0\)</span></strong> represents the intercept (the value of Y when X = Zero).</p>
								<p><strong><span class="math inline">\({\beta}_1\)</span></strong> is the coefficient (slope term) representing the linear relationship.</p>
								<p><strong><span class="math inline">\(\epsilon\)</span></strong> represents the error term (Normally distributed/Constant Variance).</p>

								<p>The simple linear regression is established upon the following assumptions:</p>

								<ul>
									<li><strong>Linear:</strong> the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> is linear.</li>
									<li><strong>Independent:</strong> the errors <span class="math inline">\(\epsilon\)</span> are independent.</li>
									<li><strong>Normal:</strong> the errors <span class="math inline">\(\epsilon\)</span> are noramlly distributed.</li>
									<li><strong>Equal Variance:</strong> the variance of <span class="math inline">\(Y\)</span> is the same at each value of <span class="math inline">\(X\)</span>.</li>
									</ul>

								<h2>Least Squares Method</h2>

								<p>If we know the population parameters <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>β<!-- ?? --></mi> <mn>0</mn> </msub> </math> and <math xmlns="http://www.w3.org/1998/Math/MathML"> <msub> <mi>β<!-- ?? --></mi> <mn>1</mn> </msub> </math>, we could use the simple linear regression model where</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"> <mtext>E</mtext> <mo stretchy="false">[</mo> <msub> <mi>Y</mi> <mi>i</mi> </msub> <mo>∣<!-- ∣ --></mo> <msub> <mi>X</mi> <mi>i</mi> </msub> <mo>=</mo> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo stretchy="false">]</mo> <mo>=</mo> <msub> <mi>β<!-- β --></mi> <mn>0</mn> </msub> <mo>+</mo> <msub> <mi>β<!-- β --></mi> <mn>1</mn> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>.</mo> </math>



<p style='text-align: justify;'>However, in reality we almost never have the parameters and thus we should estimate the value of <span class="math inline">\(Y\)</span> at every given value of <span class="math inline">\(X\)</span>
</p>
<p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"> <mrow class="MJX-TeXAtom-ORD"> <mover> <mi>y</mi> <mo stretchy="false">^<!-- ^ --></mo> </mover> </mrow> <mo>=</mo> <msub> <mrow class="MJX-TeXAtom-ORD"> <mover> <mi>β<!-- β --></mi> <mo stretchy="false">^<!-- ^ --></mo> </mover> </mrow> <mn>0</mn> </msub> <mo>+</mo> <msub> <mrow class="MJX-TeXAtom-ORD"> <mover> <mi>β<!-- β --></mi> <mo stretchy="false">^<!-- ^ --></mo> </mover> </mrow> <mn>1</mn> </msub> <mi>x</mi> <mo>.</mo> </math></p>
<p>where:</p>
<p><span class="math inline">\(\hat{y}\)</span> refers to the mean value of <span class="math inline">\(Y\)</span> for a given value of <span class="math inline">\(X\)</span></p>
<p style="text-align: justify;">
<strong>The Least Squares Method</strong> is the statistical approach that can be used to minimize the sum of all the squared distances between the observed <span class="math inline">\(y\)</span> and the predicted <span class="math inline">\(\hat{y}\)</span> at each given value of <span class="math inline">\(x\)</span>
</p>

<img src="../images/linear.png" alt="">

<p style="text-align: justify;">
	Using the image above, <strong>Least Squares Method</strong> is a mathematical technique through which we can find the value of <span class="math inline">\({\beta}_0\)</span> (intercept) and <span class="math inline">\({\beta}_1 (slope)\)</span> in order to draw a line that fits the data in a way minimizing the squared distances between the observed <span class="math inline">\(y\)</span> and the predicted <span class="math inline">\(\hat{y}\)</span>, namely the squared distances between the red points and the blue line (squared errors).
	</p>
	<p><span class="math display">\[
	{\beta}_1 = \frac{\sum_{i = 1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^{n}(x_i - \bar{x})^2}
	\]</span> and the intercept is:</p>
	<p><span class="math display">\[
	{\beta}_0 = \bar{y} - {\beta}_1 \bar{x}
	\]</span></p>
	
	<h2>Estimating the Consumption Equation</h2>
	<p>
	In this post, I will use the simple linear regression to examine whether there is any relationship between the gross national disposable income (GNDI) per capita and the aggregate consumption per capita in the Palestinian Territories. I’m going to use a data extracted from the Palestinian Central Bureau of Statistics covering the period from 1994 to 2016 using 2004 as a base year. The independent variable (predictor) will be the gross national disposable income per capita while the dependent variable (response) will be the aggregate consumption per capita. The gross national disposable income refers to is the sum of the disposable incomes of all residents, and it measures the income available to the nation for final consumption and gross (or net) saving including the income comes from external sources such as remittances and international aids.
	</p>
	<p>
	Let us first load the packages needed for analysis.
	</p>

	<pre><code>library(readxl)
		library(ggplot2)
		library(PerformanceAnalytics)
		library(broom)
		library(GGally)
		library(modelr)
		library(lars)</code></pre>

	<p>Let us now import our data.</p>

	<pre><code>consumption <- read_excel("C:/Users/Rami/Desktop/gndi-con.xlsx")

		consumption</code></pre>

	<pre><code>## # A tibble: 23 x 3
		##     Year GNDIPC ConsumptionPC
		##    <dbl>  <dbl>         <dbl>
		##  1  1994  1712.         1594.
		##  2  1995  1682.         1613.
		##  3  1996  1610.         1541.
		##  4  1997  1709.         1644.
		##  5  1998  1903.         1760.
		##  6  1999  1995.         1826.
		##  7  2000  1796.         1678.
		##  8  2001  1673.         1576.
		##  9  2002  1503.         1372.
		## 10  2003  1471.         1492.
		## # ... with 13 more rows</code></pre>

	<h2>Exploratory Analysis</h2>

	<p>Before building our model, it would be a good start to get an initial snapshot of our data.</p>

	<pre><code>summary(consumption)</code></pre>

	<pre><code>##       Year          GNDIPC     ConsumptionPC 
		##  Min.   :1994   Min.   :1471   Min.   :1372  
		##  1st Qu.:2000   1st Qu.:1696   1st Qu.:1629  
		##  Median :2005   Median :1903   Median :1757  
		##  Mean   :2005   Mean   :1844   Mean   :1749  
		##  3rd Qu.:2010   3rd Qu.:1999   3rd Qu.:1876  
		##  Max.   :2016   Max.   :2274   Max.   :2056</code></pre>

	<p>Let us draw a scatter plot for data</p>

	<pre><code>p1 <- ggplot(consumption, aes(x=consumption$GNDIPC, y=consumption$ConsumptionPC)) +
		geom_point(size= 2) + theme_minimal()
	  
	  p1</code></pre>

	<img src="../images/linear1.png" alt="">

	<p>
		The scatter plot above suggests that there is a positive linear relationship existed between the two variables; the aggregate consumption per capita tends to increase along with the increase in the gross disposable income per capita.
		</p>
		<p>
		If we want to quantify the relationship’s strength between the two variables, we can use the correlation formula:
		</p>
		<p><span class="math display">\[
		r = \frac{\sum_{i = 1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i = 1}^{n}(x_i - \bar{x})^2  (y_i - \bar{y})^2}
		\]</span></p>

	<pre><code>#Transforming the variables into integers

		consumption$`GNDI PC` <- as.integer(consumption$GNDIPC)
		consumption$`Consumption PC` <- as.integer(consumption$ConsumptionPC)</code></pre>

	<pre><code>cor(consumption$GNDIPC, consumption$ConsumptionPC)</code></pre>

	<pre><code>## [1] 0.7828823</code></pre>

	<pre><code>chart.Correlation(consumption[, c("GNDIPC", "ConsumptionPC")])</code></pre>

	<img src="../images/linear2.png" alt="">

	<p>The plot above shows that the relationship between the two variables is fairly strong. Now we are going to build our mode</p>

	<h2>Building the Linear Model</h2>

	<p>
		We can build our model using <strong>‘lm’</strong> function in R which stands for “Linear Model”. This function will produce the best-fit linear relationship by minimizing the least squares. In other words, the <strong>‘lm’</strong> funtion will enable us to estimate the value of coefficents (Slope and Intercept) in addition to the fitted values of <span class="math inline">\(y\)</span> for each value of <span class="math inline">\(x\)</span>.
		</p>

	<pre><code>model <- lm(consumption$ConsumptionPC ~ consumption$GNDIPC)</code></pre>

	<pre><code>summary(model)</code></pre>

	<pre><code>## 
		## Call:
		## lm(formula = consumption$ConsumptionPC ~ consumption$GNDIPC)
		## 
		## Residuals:
		##     Min      1Q  Median      3Q     Max 
		## -302.78  -57.95  -16.59   95.65  163.16 
		## 
		## Coefficients:
		##                    Estimate Std. Error t value Pr(>|t|)    
		## (Intercept)        539.3833   211.0807   2.555   0.0184 *  
		## consumption$GNDIPC   0.6560     0.1138   5.766 1.01e-05 ***
		## ---
		## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
		## 
		## Residual standard error: 112.6 on 21 degrees of freedom
		## Multiple R-squared:  0.6129, Adjusted R-squared:  0.5945 
		## F-statistic: 33.25 on 1 and 21 DF,  p-value: 1.006e-05</code></pre>

	<h2>Assessing Coefficients</h2>

	<p>Given the estimates that we got from the model, we can now establish our fitted regression:</p>

	<p><span class="math display">\[Y = 539 + 0.656X + e\]</span></p>

	<p>And we can get a tidy version of our model by using function “tidy” from broom package.</p>

	<pre><code>tidy(model)</code></pre>

	<pre><code>## # A tibble: 2 x 5
		##   term               estimate std.error statistic   p.value
		##   <chr>                 <dbl>     <dbl>     <dbl>     <dbl>
		## 1 (Intercept)         539.      211.         2.56 0.0184   
		## 2 consumption$GNDIPC    0.656     0.114      5.77 0.0000101</code></pre>

	<p>The table above shows that our intercept estimate is 539, so when gross national income per capita is zero, we can expect aggregate consumption per capita to be 539. The table also shows that the slope estimate is 0.656, which means that for every increase of one dollar in gross national disposable income per capita, we expect the aggregate consumption per capita to increase by $0.656. But are these coefficients statistically significant? We can examine this by computing the standard error at 95% confidence interval for the coefficients.</p>

	<pre><code>confint(model)</code></pre>

	<pre><code>##                          2.5 %      97.5 %
		## (Intercept)        100.4169983 978.3495059
		## consumption$GNDIPC   0.4194393   0.8926405</code></pre>

		<p">
			The table above shows that our 95% confidence interval for <span class="math inline">\({\beta}_1\)</span> is [0.419,0.892]. Since zero is not included in the interval, we can conclude that as gross national disposable income per capita increases by $1, the aggregate consumption per capita is going to increase by 0.419-0.892 dollars.
			</p>

	<h2>Assessing the Godness-of-Fit</h2>

	<p>
		We should ask ourselves now: <strong>How well the model fits our data?</strong>. In order to answer this question, we are going to compute two things:
		</p>
		<p>1- Residual Standard Error (RSE).</p>
		<p>2- R-Squared (<span class="math inline">\(R^2\)</span>).</p>
		<p>
		<strong>Residual Standard Error (RSE)</strong>: refers to the estimate of the standard deviation of <span class="math inline">\(\epsilon\)</span>. It provides us with the average distance the observed values deviate from the regression line measured by the units of response variable. RSE takes the following formula:
		</p>
		<p><span>\[RSE = \sqrt{\frac{1}{n-2}\sum^n_{i=1}(y_i - \hat{y}_i)^2}\]</span></p>
		<p>
		We can get the value of RSE in R using sigma function from broom package.
		</p>

	<pre><code>sigma(model)</code></pre>

	<pre><code>## [1] 112.6039</code></pre>

	<p>RSE value of 112.60 means that the actual aggregate consumption per capita will deviate from the true regression line by approximately $112.60, on average. As RSE is an absolute value that does not explain so much by itself, it might be a good idea to compare it with the mean of the aggregate consumption per capita.</p>

	<pre><code>sigma(model)/mean(consumption$ConsumptionPC)</code></pre>

	<pre><code>## [1] 0.06438247</code></pre>

	<p>We got a percentage error of 6.1% when we compare the RSE to the mean of the response variable. This percentage suggests that our model fits the data well as the deviation of the response variable from the regression line is not so big.</p>

	<p>
		<strong>R-Squared (<span class="math inline">\(R^2\)</span>)</strong>: expresses the proportion of the variance in the dependent variable (response) that is “explained” by the model. That is, the variation in aggregate consumption per capita due to the changes in the gross national disposable income per capita. In order to fully understand the logic behind <span class="math inline">\(R^2\)</span>, let us first introduce three important formulas.
		</p>
		<p>
		<strong>1- Sum of Squares Total</strong>: refers to the <strong>total</strong> variation of the observed values of <span class="math inline">\(y\)</span>
		</p>
		<p><span class="math display">\[\text{SST} = \sum_{i=1}^{n}(y_i - \bar{y})^2\]</span></p>
		<p>
		<strong>2- Sum of Squares Regression</strong>: refers to the <strong>explained</strong> variation of the observed values of <span class="math inline">\(y\)</span>
		</p>
		<p><span class="math display">\[\text{SSR} = \sum_{i=1}^{n}(\hat{y}_i - \bar{y})^2\]</span></p>
		<p>
		<strong>3- Sum of Squares Error</strong>: refers to the <strong>unexplained</strong> variation of the observed values of <span class="math inline">\(y\)</span>
		</p>
		<p><span class="math display">\[\text{SSE} = \sum_{i=1}^{n}(y_i - \hat{y}_i)^2\]</span></p>
		<p>
		Since <span class="math inline">\(R^2\)</span> measures the variation in the response variable that is <strong>explained</strong> by the model, it thus takes the following formula:
		</p>
		<p><span class="math display">\[R^2 =  \frac{SSR}{SST}= \frac{\sum^n_{i=1}(y_i-\hat{y}_i)^2}{\sum^n_{i=1}(y_i-\bar{y}_i)^2}\]</span></p>
		<p>
		<span class="math inline">\(R^2\)</span> for our model is equal to 0.6129, which means that 61% of the variability in the aggregate consumption per capita can be explained by the gross national disposable income per capita.
		</p>

	<h2>Residual Analysis</h2>

	<p>
		Only part of the variation in the dependent variable will be explained by the values of the independent variable SSR/SST (which is equal to 0.61 in our model). The variation left unexplained is due to the error SSE/SST, and this is why we should also conduct an analysis on the residuals of our model. The main issue here is to make sure that the residuals are following the assumptions of the linear regression. The residuals analysis can be made through 4-plots grid in R.
		</p>
		<p>
		<strong>Residuals Vs. Fitted Values</strong>: This plot shows if the residuals have a non-linear pattern. If the residuals spread around the horizontal lines without showing specific patter, this can be deemed as a sign of the model’s linearity.
		</p>
		<p>
		<strong>Normal Q-Q</strong>: This plot is concerned with the normal distribution of the residuals. If the residuals follow a straight line and do not deviate far from the line, this should be a good indication that the residuals are normally distributed.
		</p>
		<p>
		<strong>Scale-Location</strong>: This plot shows if the residuals are spread equally along with the fitted values. This plot enables us to make sure that the assumption of homoscedasticity (equal variance of residuals). If the residuals are randomly spread, this should be a good sign that the residuals have the same variance for all values of the predictor variable.
		</p>
		<p>
		<strong>Residuals Vs. Leverage</strong>: This plot enables us to detect the influential cases. The data might include extreme values, however; these values can be with no influential impact on our regression line. On the other hand, some values that lay within the range of the data might be very influential. If the cases are outside of the Cook’s distance (namely outside of a dashed line), the cases are influential to the regression results.
		</p>

	<pre><code>par(mfrow = c(2, 2))
		plot(model)</code></pre>

	<img src="../images/residual-analysis.png" alt="">

	<p>The four plots of our model show that the residuals almost have no specific pattern around the horizontal line, suggesting that the relationship between the response and the predictor variables is linear. The plots also indicate that most residuals fall on the Q-Q line, suggesting that the residuals are normally distributed. However, Residuals Vs. Leverage plot clearly shows that data point No. 15 is an outlier that has a large impact on our model. This can be seen in all other three plots where point 15 deviates far from the other data points.</p>

	<p>Let us dig deeper in our data to see how point 15 had such impact on our model. I’m going to extract the observed and fitted values of response variable in addition to the residuals.</p>

	<pre><code>as.data.frame(consumption$ConsumptionPC)</code></pre>

	<pre><code>##    consumption$ConsumptionPC
		## 1                    1593.69
		## 2                    1613.10
		## 3                    1540.68
		## 4                    1644.10
		## 5                    1759.82
		## 6                    1825.60
		## 7                    1677.54
		## 8                    1575.81
		## 9                    1371.70
		## 10                   1491.72
		## 11                   1668.29
		## 12                   1811.48
		## 13                   1703.54
		## 14                   1757.46
		## 15                   1728.48
		## 16                   1796.31
		## 17                   1812.00
		## 18                   1934.08
		## 19                   2056.45
		## 20                   1926.78
		## 21                   1938.37
		## 22                   1999.78
		## 23                   1999.85</code></pre>

	<pre><code>(model$fitted.values)</code></pre>

	<pre><code>##        1        2        3        4        5        6        7        8 
		## 1662.609 1642.829 1595.581 1660.693 1787.893 1848.360 1717.933 1636.813 
		##        9       10       11       12       13       14       15       16 
		## 1525.457 1504.457 1558.541 1706.327 1665.830 1852.860 2031.257 1893.732 
		##       17       18       19       20       21       22       23 
		## 1802.149 1796.192 1893.286 1840.638 1828.823 1859.119 1915.250</code></pre>

	<pre><code>(model$residuals)</code></pre>

	<pre><code>##           1           2           3           4           5           6 
		##  -68.918844  -29.729241  -54.901248  -16.593208  -28.072784  -22.759981 
		##           7           8           9          10          11          12 
		##  -40.392689  -61.003355 -153.757143  -12.737306  109.748765  105.152657 
		##          13          14          15          16          17          18 
		##   37.710000  -95.400415 -302.777345  -97.421701    9.851469  137.888312 
		##          19          20          21          22          23 
		##  163.164406   86.141608  109.546887  140.660964   84.600191</code></pre>

	<p>As we can see, though the observed value of response variable at point 15 equals to 1728.48 (which lies within a reasonable range of our data), it’s fitted value equals to 2031.257. That is, 1728.48 (observed) - 2031.257 (fitted) = -302.777345 (residual) which looks high comparing to other residuals for other fitted values in our model. This confirms the wisdom that some values that look “reasonable” within the range of the data might be very influential after fitting the model.</p>

	<h2>Excluding the Outlier</h2>

	<p>Excluding the outlier from the model might not be the best approach to deal with its impact, however, for the purpose of this project, I’m going to omit the outlier from the data in order to examine how this step can improve the quality of the model.</p>

	<p>Let us import our new data without outlier.</p>

	<pre><code>consumption_new <- read_excel("C:/Users/Rami/Desktop/pcon.xlsx")</code></pre>

	<pre><code>#Transforming the variables into integers

		consumption_new$`GNDI PC` <- as.integer(consumption_new$GNDIPC)
		consumption_new$`Consumption PC` <- as.integer(consumption_new$ConsumptionPC)</code></pre>

	<pre><code>chart.Correlation(consumption_new[, c("GNDIPC", "ConsumptionPC")])</code></pre>

	<img src="../images/outlier.png" alt="">

	<p>We can notice that the exclusion of the outlier results in increasing the correlation between the independent and the dependent variables from 0.78 to 0.89. In other words, omitting the impact of the outlier makes the positive relationship between the two variables much stronger.</p>

	<p>Let us now build a new model and assess the coefficients and the goodness of fit.</p>

	<pre><code>model2 <- lm(consumption_new$ConsumptionPC ~ consumption_new$GNDIPC)
		summary(model2)</code></pre>

	<pre><code>## 
		## Call:
		## lm(formula = consumption_new$ConsumptionPC ~ consumption_new$GNDIPC)
		## 
		## Residuals:
		##     Min      1Q  Median      3Q     Max 
		## -152.80  -53.96  -14.63   64.68  142.90 
		## 
		## Coefficients:
		##                         Estimate Std. Error t value Pr(>|t|)    
		## (Intercept)            237.05890  177.24502   1.337    0.196    
		## consumption_new$GNDIPC   0.82931    0.09664   8.581 3.88e-08 ***
		## ---
		## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
		## 
		## Residual standard error: 85.68 on 20 degrees of freedom
		## Multiple R-squared:  0.7864, Adjusted R-squared:  0.7757 
		## F-statistic: 73.64 on 1 and 20 DF,  p-value: 3.88e-08</code></pre>

	<p>The new model after excluding the outlier is the following:</p>

	<p><span class="math display">\[Y = 237 + 0.829X + e\]</span></p>

	<p>We can see that the slope of the regression line has been increased from 0.656 to 0.829, which means that for every increase of one dollar in gross national disposable income per capita, we expect the aggregate consumption per capita to increase by $0.829, on average.</p>

	<pre><code>sigma(model2)</code></pre>

	<pre><code>## [1] 85.68321</code></pre>

	<pre><code>sigma(model2)/mean(consumption_new$ConsumptionPC)</code></pre>

	<pre><code>## [1] 0.04896419</code></pre>

	<p>
		Omitting the outlier has also resulted in decreasing the Residual Standard Error from 112.60 in the previous model to 85.68 in the current one. <span class="math inline">\(R^2\)</span> has also increased to 0.78, suggesting that the model without outlier has much stronger explanatory power.
	</p>

	<h2>Residual Analysis</h2>

	<p>We will now examine how the residuals behave after the exclusion of the outlier from the model using the grid of 4-plots used previously.</p>

	<pre><code>par(mfrow = c(2, 2))
		plot(model2)</code></pre>

	<img src="../images/residual-analysis2.png" alt="">

	<p>We can clearly see from the plots above that the exclusion of the outlier has improved the performance of the residuals. The plot of Residuals Vs. Fitted values suggests that the relationship between the dependent variable and the independent variable is linear. The Q-Q plot shows that the residuals are normally distributed with no significant deviations from the line. The plot of scale-location indicates that the residuals are not spread equally along the range of predictors as they look somewhat heteroscedastic in the middle and the end of the range. However, it could be quite difficult to confirm such conclusion with small set of data as the one under consideration.</p>

	<h2>Making Predictions</h2>

	<p>
		One of the advantages of the linear regression lies in its ability to be a predictive model. However, when we try to use the regression to make predictions, we should take into account two concepts, the first one is <strong>interpolation</strong> and the second one is <strong>extrapolation</strong>. The interpolation refers to the process where the prediction is made upon a data point that is not an observed value of the independent variable but it lies within the data range. The extrapolation refers to the process where the prediction is made based on a point outside the data range.
		</p>




								





								
								




								





                                

                                




                            
                      

                           
                        
 









																					






								



								


								</section>

							</div>


					<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>
			<script src="../assets/js/highlight.pack.js"></script>
			<script>hljs.initHighlightingOnLoad();</script>

	</body>
</html>